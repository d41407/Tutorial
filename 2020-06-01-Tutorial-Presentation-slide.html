<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tutorial</title>
    <meta charset="utf-8" />
    <meta name="author" content="HJ WU &amp; CY Chang" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Tutorial
## Using R to analyze international large-scale educational assessment data
### HJ WU &amp; CY Chang
### Public Health &amp; Education
### 2020/06/01

---




---
# Outline

## Why we chose this topic (Chang)    
## Import data &amp; Data wrangling (Wu)
#### Select and merge data 
#### Data wrangling 
## Descriptive analysis(Chang)  
#### Mean and Frequency  
## Regression analysis  (Wu)
## Data visualization  (Wu)

---
class: inverse, center

# Why we chose this topic

## What is PISA?

### 1. The international evaluation execute by OECD (經濟合作暨發展組織)

### 2. Object: 15 years Students. (math, read, science)
--

## Why we chose this topic?

### 1. Researchers often analyze PISA to understand students' learning environment. Take this result to improve education.

### 2. Practice how to analyze Big data.

---

# Import data &amp; Data wrangling (1)

### Select data and merge 
  
- **Install the** [**EdSurvey**](https://www.rdocumentation.org/packages/EdSurvey/versions/2.4.0) **package:**


```r
install.packages("EdSurvey")
```
--

**download, unzip and read the PISA data**

```r
library(EdSurvey)
downloadPISA(years = 2012, database ="INT", 
             root="C:/Users/X510/Desktop/PISA-2012") 
```

```
## 
## Processing PISA data for year 2012
## Database INT
## Found downloaded 2012 PISA (INT database) file INT_STU12_DEC03.zip.
## Found downloaded 2012 PISA (INT database) file INT_SCQ12_DEC03.zip.
## Found downloaded 2012 PISA (INT database) file INT_PAQ12_DEC03.zip.
## Found downloaded 2012 PISA (INT database) file INT_COG12_DEC03.zip.
## Found downloaded 2012 PISA (INT database) file INT_COG12_S_DEC03.zip.
## Found downloaded 2012 PISA (INT database) file PISA2012_SPSS_student.txt.
## Found downloaded 2012 PISA (INT database) file PISA2012_SPSS_school.txt.
## Found downloaded 2012 PISA (INT database) file PISA2012_SPSS_parent.txt.
## Found downloaded 2012 PISA (INT database) file PISA2012_SPSS_cognitive_item.txt.
## Found downloaded 2012 PISA (INT database) file PISA2012_SPSS_scored_cognitive_item.txt.
## Unzipping 2012 PISA (INT database) files from C:/Users/X510/Desktop/PISA-2012/PISA/2012/INT_COG12_DEC03.zip
## Unzipping 2012 PISA (INT database) files from C:/Users/X510/Desktop/PISA-2012/PISA/2012/INT_COG12_S_DEC03.zip
## Unzipping 2012 PISA (INT database) files from C:/Users/X510/Desktop/PISA-2012/PISA/2012/INT_PAQ12_DEC03.zip
## Unzipping 2012 PISA (INT database) files from C:/Users/X510/Desktop/PISA-2012/PISA/2012/INT_SCQ12_DEC03.zip
## Unzipping 2012 PISA (INT database) files from C:/Users/X510/Desktop/PISA-2012/PISA/2012/INT_STU12_DEC03.zip
```

```r
pisa12&lt;-readPISA(path = "C:/Users/X510/Desktop/PISA-2012/PISA/2012", 
                 database = "INT", 
                 countries = c("AUS","CAN","DEU","ESP","FIN","FRA","GBR",
                               "IDN","ITA","JPN","MEX","MYS","NZL","TAP","USA"), 
                 verbose = T)
```

```
## Found cached data for country code "aus"
## Found cached data for country code "can"
## Found cached data for country code "deu"
## Found cached data for country code "esp"
## Found cached data for country code "fin"
## Found cached data for country code "fra"
## Found cached data for country code "gbr"
## Found cached data for country code "idn"
## Found cached data for country code "ita"
## Found cached data for country code "jpn"
## Found cached data for country code "mex"
## Found cached data for country code "mys"
## Found cached data for country code "nzl"
## Found cached data for country code "tap"
## Found cached data for country code "usa"
```

---
# Import data &amp; Data wrangling (2)  
### Select data and merge 

**Select variable**

```r
pisa12raw&lt;-getData(pisa12, 
                   varnames=c("cnt","schoolid","stidstd","questid","bookid",
                              "st04q01","st28q01","st13q01","st26q01","st26q02",
                              "st26q03","st26q04","st26q05","st26q06","st26q07",
                              "st26q08","st26q09","st26q10","st26q11","st26q12",
                              "st26q13","st26q14","w_fstuwt","math", "macc", 
                              "macq", "macs", "macu", "mape", "mapf", "mapi",
                              "read", "scie"), 
               dropUnusedLevels = TRUE, # keep unusedLevels
               omittedLevels = FALSE,   # keep Levels
               defaultConditions = TRUE,
               formula = NULL,
               recode = NULL,
               includeNaLabel = FALSE,
               addAttributes = FALSE)
```



---

# Import data &amp; Data wrangling (3)  
## Data wrangling

**Turn to data frame**

```r
pisa.dt&lt;-do.call(rbind, pisa12raw)
str(pisa.dt, list.len=8)
```

```
# 'data.frame':	189804 obs. of  153 variables:
#  $ cnt     : Factor w/ 15 levels "Australia","Canada",..: 1 1 1 1 1 1 1 1 1 1 ...
#  $ schoolid: num  1 1 1 1 1 1 1 1 1 1 ...
#  $ stidstd : num  1 2 3 4 5 6 7 8 9 10 ...
#  $ questid : Factor w/ 4 levels "StQ Form A","StQ Form B",..: 3 3 1 1 3 2 2 2 2 3 ...
#  $ bookid  : Factor w/ 21 levels "booklet 1","booklet 2",..: 11 9 7 12 5 2 7 10 8 3 ...
#  $ st04q01 : Factor w/ 2 levels "Female","Male": 1 1 1 2 2 1 1 2 2 2 ...
#  $ st28q01 : Factor w/ 9 levels "0-10 books","11-25 books",..: 5 3 5 5 3 3 6 5 4 3 ...
#  $ st13q01 : Factor w/ 8 levels "&lt;ISCED level 3A&gt;",..: 1 3 7 1 1 2 1 1 1 1 ...
#   [list output truncated]
```
---
# Import data &amp; Data wrangling (4)  
## Data wrangling

**Rename the variable**

```r
# aligned with the format of intsvy package
names(pisa.dt) &lt;- toupper(names(pisa.dt))
# dealing with different NA value
levels(pisa.dt$ST28Q01)[levels(pisa.dt$ST28Q01)%in% 
                          c("N/A", "Invalid", "Missing")]&lt;-NA
levels(pisa.dt$ST13Q01)[levels(pisa.dt$ST13Q01)%in% 
                          c("N/A", "Invalid", "Missing")]&lt;-NA
```

---
# Import data &amp; Data wrangling (5)  
## Data wrangling
**Recode**

```r
library(dplyr)
pisa.dt[, 6:22]&lt;-sapply(pisa.dt[ ,6:22], function(x) as.numeric(x)) 
pisa.dt&lt;-pisa.dt%&gt;%mutate(Country_ID=as.factor(.$CNT),
         Gender=factor(abs(as.numeric(.$ST04Q01)-1), 
                      levels=c(0,1), labels=c("F","M")),
         Book=as.numeric(.$ST28Q01),
         Mother=abs(.$ST13Q01-6))
```

--

**orginal code**

```r
dta$CNT&lt;-as.factor(dta$CNT)
for(i in 4:20) {
dta[,i] &lt;- as.numeric(dta[,i])
} 
dta$Gender&lt;-dta$ST04Q01
dta$Gender&lt;-factor(dta$Gender, levels=c(0,1), labels=c("F","M"))
dta$Book&lt;-dta$ST28Q01 
dta$Mother&lt;-dta$ST13Q01
```

---
# Import data &amp; Data wrangling (6)  
## Data wrangling
**Create new variables:posseission **

**Revised code**

```r
# stq2601-stq2614  recode "Yes"==1, "No"==0 
cols.num &lt;- c(paste0(rep("ST26Q0", 9),seq(1,9,by=1), sep=""),
              paste0(rep("ST26Q", 5),seq(10,14,by=1), sep=""))
pisa.dt[cols.num] &lt;-sapply(pisa.dt[cols.num], function(x) abs(x-2))
# Possessions is sum of ST26Q01 to ST26Q14
pisa.dt$Possessions&lt;-rowSums(pisa.dt[cols.num])
```
--
**Original code**

```r
for(i in 6:19) {dta[,i] &lt;- abs(dta[,i]-2)}
dta$Possessions&lt;-dta$ST26Q01+dta$ST26Q02+dta$ST26Q03+dta$ST26Q04
+dta$ST26Q05+dta$ST26Q06+dta$ST26Q07+dta$ST26Q08+dta$ST26Q09
+dta$ST26Q10+dta$ST26Q11+dta$ST26Q12+dta$ST26Q13+dta$ST26Q14 
```

---

# Descriptive analysis 
## Frequency
**install package "intsvy", it can produce descriptive table**

```r
# install the package, it can manipulate PISA data
library(intsvy)
```

--

**pisa.table: Produce frequency table according to variables**

```r
# Produce frequency table according to Country &amp; Gender
ptableCB &lt;- pisa.table(variable="Book", by=c("Country_ID", "Gender"), data=pisa.dt)
head(ptableCB)# Show data
```

```
##   Country_ID Gender Book Freq Percentage Std.err.
## 1  Australia      F    1  679       8.93     0.48
## 2  Australia      F    2  898      12.42     0.50
## 3  Australia      F    3 2039      29.95     0.60
## 4  Australia      F    4 1431      21.30     0.59
## 5  Australia      F    5 1245      18.60     0.66
## 6  Australia      F    6  609       8.80     0.42
```

---


```r
# alternative table display
knitr::kable(head(ptableCB), align = "cc", format = "html") # align to center
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Country_ID &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Gender &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Book &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Freq &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Percentage &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Std.err. &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Australia &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; F &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 679 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8.93 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.48 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Australia &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; F &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 898 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 12.42 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.50 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Australia &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; F &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2039 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 29.95 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.60 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Australia &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; F &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1431 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 21.30 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.59 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Australia &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; F &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1245 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 18.60 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.66 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; Australia &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; F &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 609 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 8.80 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.42 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# Descriptive analysis 
## Frequency
**plot: Plot the frequency table**

.pull-left[

```r
plot(na.omit(ptableCB), stacked=T)
```

```r
#stacked=T: Stack the histogram
#na.omit: Omit NA
```
]

.pull-right[
![](2020-06-01-Tutorial-Presentation-slide_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;
]

--

德國(DEU)：The most students whose Book collection &gt; 500. On the countrary: 墨西哥(MEX).

---

# Descriptive analysis 
## Mean
**pisa.mean.pv: Produce mean table according to variables**


```r
# Produce mean table according to Country &amp; Gender &amp; Book
pmeansMCGB &lt;- pisa.mean.pv(pvlabel="MATH",
                           by=c("Country_ID", "Gender", "Book"),
                           data=pisa.dt,
                           export=FALSE)# output csv. file
head(ptableCB)#show data
```

```
##   Country_ID Gender Book Freq Percentage Std.err.
## 1  Australia      F    1  679       8.93     0.48
## 2  Australia      F    2  898      12.42     0.50
## 3  Australia      F    3 2039      29.95     0.60
## 4  Australia      F    4 1431      21.30     0.59
## 5  Australia      F    5 1245      18.60     0.66
## 6  Australia      F    6  609       8.80     0.42
```

---

# Descriptive analysis 
## Mean
**plot: Plot the mean table**

.pull-left[

```r
plot(na.omit(pmeansMCGB), sort=TRUE)
```

```r
#sort: list data in order
#na.omit: Omit NA
```
]

.pull-right[
![](2020-06-01-Tutorial-Presentation-slide_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;
]

--

Tanwan's math score are higher than other countries.
On the countrary: Indonesia.

---

# Descriptive analysis 
## Descriptive table
**install package "arsenal", it can produce descriptive table**

```r
library(arsenal)
library(DT)
```


```r
# Choose variables which you want to put in the table.
tab_select &lt;- pisa.dt[,c("Country_ID","Gender","Book","Possessions","Mother")]
str(tab_select)
```

```
## 'data.frame':	189804 obs. of  5 variables:
##  $ Country_ID : Factor w/ 15 levels "Australia","Canada",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Gender     : Factor w/ 2 levels "F","M": 1 1 1 2 2 1 1 2 2 2 ...
##  $ Book       : num  5 3 5 5 3 3 6 5 4 3 ...
##  $ Possessions: num  12 9 12 13 11 11 13 11 14 13 ...
##  $ Mother     : num  5 3 NA 5 5 4 5 5 5 5 ...
```

---

# Descriptive analysis 
## Descriptive table

**Setting**

```r
controls &lt;- tableby.control(
  total = T,
  numeric.stats = c("meansd", "medianq1q3", "range", "Nmiss2"),#setting numeric variables 
  cat.stats = c("countpct", "Nmiss2"),#setting category variables 
  stats.labels = list(
   meansd = "Mean (SD)",
   medianq1q3 = "Median (Q1, Q3)",
   range = "Min - Max",
   Nmiss2 = "Missing"))
```

---

# Descriptive analysis 
## Descriptive table
**Show table**

```r
table &lt;- tableby(Country_ID ~ ., data = tab_select, control = controls) #Categorize by Country

summary(table, text=TRUE, title = "Descriptive table by Country")
```

```
## 
## Table: Descriptive table by Country
## 
## |                   |  Australia (N=14481)   |    Canada (N=21544)    |    Germany (N=5001)     |     Spain (N=25313)     |    Finland (N=8829)     |    France (N=4613)     | United Kingdom (N=12659) |  Indonesia (N=5622)  |     Italy (N=31073)     |    Japan (N=6351)     |   Mexico (N=33806)    |   Malaysia (N=5197)   |  New Zealand (N=4291)  | Chinese Taipei (N=6046) | United States of America (N=4978) |    Total (N=189804)    | p value|
## |:------------------|:----------------------:|:----------------------:|:-----------------------:|:-----------------------:|:-----------------------:|:----------------------:|:------------------------:|:--------------------:|:-----------------------:|:---------------------:|:---------------------:|:---------------------:|:----------------------:|:-----------------------:|:---------------------------------:|:----------------------:|-------:|
## |Gender             |                        |                        |                         |                         |                         |                        |                          |                      |                         |                       |                       |                       |                        |                         |                                   |                        | &lt; 0.001|
## |-  F               |      7075 (48.9%)      |     10943 (50.8%)      |      2462 (49.2%)       |      12690 (50.1%)      |      4370 (49.5%)       |      2375 (51.5%)      |       6308 (49.8%)       |     2860 (50.9%)     |      15243 (49.1%)      |     3021 (47.6%)      |     17553 (51.9%)     |     2745 (52.8%)      |      2131 (49.7%)      |      3111 (51.5%)       |           2453 (49.3%)            |     95340 (50.2%)      |        |
## |-  M               |      7406 (51.1%)      |     10601 (49.2%)      |      2539 (50.8%)       |      12623 (49.9%)      |      4459 (50.5%)       |      2238 (48.5%)      |       6351 (50.2%)       |     2762 (49.1%)     |      15830 (50.9%)      |     3330 (52.4%)      |     16253 (48.1%)     |     2452 (47.2%)      |      2160 (50.3%)      |      2935 (48.5%)       |           2525 (50.7%)            |     94464 (49.8%)      |        |
## |-  Missing         |           0            |           0            |            0            |            0            |            0            |           0            |            0             |          0           |            0            |           0           |           0           |           0           |           0            |            0            |                 0                 |           0            |        |
## |Book               |                        |                        |                         |                         |                         |                        |                          |                      |                         |                       |                       |                       |                        |                         |                                   |                        | &lt; 0.001|
## |-  Mean (SD)       |     3.450 (1.435)      |     3.405 (1.397)      |      3.558 (1.446)      |      3.592 (1.399)      |      3.346 (1.338)      |     3.127 (1.469)      |      3.154 (1.456)       |    2.320 (1.152)     |      3.272 (1.426)      |     3.431 (1.366)     |     1.943 (1.111)     |     2.873 (1.233)     |     3.437 (1.427)      |      3.225 (1.450)      |           2.867 (1.421)           |     3.064 (1.471)      |        |
## |-  Median (Q1, Q3) |  3.000 (3.000, 5.000)  |  3.000 (3.000, 4.000)  |  3.000 (3.000, 5.000)   |  3.000 (3.000, 5.000)   |  3.000 (3.000, 4.000)   |  3.000 (2.000, 4.000)  |   3.000 (2.000, 4.000)   | 2.000 (1.000, 3.000) |  3.000 (2.000, 4.000)   | 3.000 (3.000, 4.000)  | 2.000 (1.000, 3.000)  | 3.000 (2.000, 4.000)  |  3.000 (3.000, 5.000)  |  3.000 (2.000, 4.000)   |       3.000 (2.000, 4.000)        |  3.000 (2.000, 4.000)  |        |
## |-  Min - Max       |     1.000 - 6.000      |     1.000 - 6.000      |      1.000 - 6.000      |      1.000 - 6.000      |      1.000 - 6.000      |     1.000 - 6.000      |      1.000 - 6.000       |    1.000 - 6.000     |      1.000 - 6.000      |     1.000 - 6.000     |     1.000 - 6.000     |     1.000 - 6.000     |     1.000 - 6.000      |      1.000 - 6.000      |           1.000 - 6.000           |     1.000 - 6.000      |        |
## |-  Missing         |          386           |          641           |           843           |           381           |           171           |          129           |           240            |         139          |           471           |          126          |         1020          |          41           |          109           |           31            |                89                 |          4817          |        |
## |Possessions        |                        |                        |                         |                         |                         |                        |                          |                      |                         |                       |                       |                       |                        |                         |                                   |                        | &lt; 0.001|
## |-  Mean (SD)       |     11.544 (4.391)     |     11.348 (3.817)     |     12.893 (4.847)      |     11.672 (3.333)      |     11.548 (3.761)      |     11.101 (3.016)     |      11.649 (4.516)      |    8.287 (6.264)     |     11.375 (2.921)      |     9.470 (2.639)     |     8.611 (5.819)     |     9.467 (4.925)     |     10.938 (4.107)     |     10.495 (4.018)      |          11.070 (4.062)           |     10.738 (4.455)     |        |
## |-  Median (Q1, Q3) | 11.000 (9.000, 13.000) | 11.000 (9.000, 13.000) | 13.000 (11.000, 14.000) | 12.000 (10.000, 13.000) | 11.000 (10.000, 13.000) | 11.000 (9.000, 13.000) |  11.000 (9.000, 13.000)  | 7.000 (5.000, 9.000) | 11.000 (10.000, 13.000) | 9.000 (8.000, 11.000) | 8.000 (5.000, 10.000) | 9.000 (7.000, 11.000) | 11.000 (9.000, 13.000) | 10.000 (8.000, 12.000)  |      11.000 (9.000, 13.000)       | 11.000 (9.000, 13.000) |        |
## |-  Min - Max       |     0.000 - 42.000     |     0.000 - 42.000     |     2.000 - 42.000      |     0.000 - 42.000      |     0.000 - 42.000      |     1.000 - 42.000     |      0.000 - 42.000      |    0.000 - 42.000    |     0.000 - 42.000      |    0.000 - 42.000     |    0.000 - 42.000     |    0.000 - 42.000     |     0.000 - 42.000     |     0.000 - 42.000      |          0.000 - 42.000           |     0.000 - 42.000     |        |
## |-  Missing         |           0            |           0            |            0            |            0            |            0            |           0            |            0             |          0           |            0            |           0           |           0           |           0           |           0            |            0            |                 0                 |           0            |        |
## |Mother             |                        |                        |                         |                         |                         |                        |                          |                      |                         |                       |                       |                       |                        |                         |                                   |                        | &lt; 0.001|
## |-  Mean (SD)       |     4.305 (0.980)      |     4.856 (0.575)      |      3.711 (0.993)      |      4.007 (1.127)      |      4.354 (0.836)      |     4.363 (0.854)      |      4.342 (0.661)       |    3.154 (1.434)     |      4.117 (0.962)      |     4.820 (0.462)     |     3.182 (1.302)     |     4.024 (1.312)     |     4.258 (0.789)      |      4.145 (0.879)      |           4.666 (0.899)           |     4.064 (1.143)      |        |
## |-  Median (Q1, Q3) |  5.000 (3.000, 5.000)  |  5.000 (5.000, 5.000)  |  3.000 (3.000, 5.000)   |  4.000 (3.000, 5.000)   |  5.000 (4.000, 5.000)   |  5.000 (4.000, 5.000)  |   4.000 (4.000, 5.000)   | 3.000 (2.000, 5.000) |  4.000 (3.000, 5.000)   | 5.000 (5.000, 5.000)  | 3.000 (2.000, 4.000)  | 5.000 (3.000, 5.000)  |  4.000 (4.000, 5.000)  |  4.000 (4.000, 5.000)   |       5.000 (5.000, 5.000)        |  5.000 (3.000, 5.000)  |        |
## |-  Min - Max       |     1.000 - 5.000      |     1.000 - 5.000      |      1.000 - 5.000      |      1.000 - 5.000      |      1.000 - 5.000      |     1.000 - 5.000      |      1.000 - 5.000       |    1.000 - 5.000     |      1.000 - 5.000      |     3.000 - 5.000     |     1.000 - 5.000     |     1.000 - 5.000     |     1.000 - 5.000      |      1.000 - 5.000      |           1.000 - 5.000           |     1.000 - 5.000      |        |
## |-  Missing         |          1196          |          996           |          1285           |          1278           |           428           |          371           |           1124           |         189          |          1227           |          345          |         1116          |          190          |          625           |           122           |                174                |         10666          |        |
```

---
class: inverse, center, middle

# Regression analysis  (Wu)

---
# Regression analysis (1)
**regression model** 

```r
library(intsvy)
rmodelMGBMP &lt;-pisa.reg.pv(pvlabel="MATH",
                          x=c("Gender","Book","Mother","Possessions"), 
                          by = "Country_ID", data=pisa.dt,
                          export=FALSE)
```
---

# Regression analysis (2)

```r
plot(rmodelMGBMP)
```

![](2020-06-01-Tutorial-Presentation-slide_files/figure-html/unnamed-chunk-22-1.png)&lt;!-- --&gt;

---
# Regression analysis (3)
**Extract estimate from regression model for further data visulization**
### 1

```r
model.e&lt;-sapply(rmodelMGBMP, "[", 5)
model.e1&lt;-bind_rows(model.e)%&gt;%mutate(country=rep(c("AUS","CAN","DEU","ESP","FIN","FRA","GBR","IDN",
                                              "ITA","JPN","MEX","MYS","NZL","TWN","USA"), each=6),
                                item=rep(rownames(model.e$Australia.reg), 15))
knitr::kable(head(model.e1), format = "html")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; t value &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; country &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; item &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 375.1298191 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.6707217 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 80.315173 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 14.9745840 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.5650159 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.838008 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; GenderM &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 22.2386042 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.7209513 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30.846193 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Book &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 13.4349737 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.9467555 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.190542 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Mother &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; -0.8690076 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2750581 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.159360 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Possessions &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0.1485925 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0072222 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20.574364 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; R-squared &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
**Extract estimate from regression model for further data visulization**


```r
# alternative method
datalist = list()

for (i in 1:15){datalist[[i]]&lt;-rmodelMGBMP[[i]]$reg}
 model&lt;-do.call(rbind, datalist)%&gt;%
  mutate(Country=rep(c("AUS","CAN","DEU","ESP","FIN","FRA","GBR","IDN","ITA","JPN","MEX","MYS", "NZL","TWN","USA"), each=6)) 
model$variable&lt;-rep(rownames(rmodelMGBMP[[1]]$reg), 15)
knitr::kable(head(model), format = "html")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Std. Error &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; t value &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Country &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; variable &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 375.1298191 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.6707217 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 80.315173 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 14.9745840 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.5650159 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.838008 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; GenderM &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 22.2386042 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.7209513 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 30.846193 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Book &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 13.4349737 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.9467555 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.190542 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Mother &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; -0.8690076 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2750581 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.159360 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Possessions &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 0.1485925 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.0072222 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20.574364 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; R-squared &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
**Extract estimate from regression model for further data visulization**

```r
library(dplyr)
model.s&lt;-model.e1%&gt;%
  dplyr::select(item, country, Estimate)%&gt;%
  tidyr::spread(item, Estimate)
model.s[order(model.s$GenderM),]
```

```
##    country (Intercept)      Book   GenderM    Mother Possessions  R-squared
## 12     MYS    347.2044 14.475734 -5.250196 10.042348  -0.4087484 0.08933360
## 8      IDN    332.9990  6.459672  3.779769  9.084871  -0.3140553 0.05209305
## 5      FIN    381.1421 22.197500  5.537962 16.998294  -1.0452136 0.15624631
## 14     TWN    414.2095 28.924442  6.383848  9.478763   1.1121534 0.15692173
## 15     USA    387.1742 24.142383  8.569645  7.007260  -0.9015748 0.15905097
## 6      FRA    309.0471 27.234683 13.547131 20.067683   1.3049297 0.28188028
## 11     MEX    357.2441 10.477143 13.881331 12.647970  -0.9680660 0.10047542
## 1      AUS    375.1298 22.238604 14.974584 13.434974  -0.8690076 0.14859248
## 2      CAN    396.9541 19.709194 15.624779 10.092246   0.1342376 0.11800774
## 7      GBR    355.7182 25.955553 16.082416 17.177781  -1.8003925 0.21716403
## 4      ESP    346.6310 23.314586 19.716569 11.241737   0.6349016 0.21839356
## 10     JPN    372.9098 11.441612 19.901755  9.673563   7.4646313 0.10664179
## 13     NZL    322.1640 22.829670 20.458152 20.240096   1.2167568 0.19994554
## 9      ITA    346.9258 20.219030 20.860775 14.142991   0.6537855 0.17216058
## 3      DEU    388.1498 26.006559 21.126381 17.193497  -2.5634198 0.23175973
```

---

```r
model.s$genderlevel&lt;-with(model.s, 
                          factor(findInterval(GenderM, c(-Inf,quantile(GenderM, probs=c(0.25, 0.75)),Inf)), labels=c("後面25%", "中間50%", "前面25%"))) 

knitr::kable(head(model.s), format = "html")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; country &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; (Intercept) &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Book &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; GenderM &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Mother &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Possessions &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; R-squared &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; genderlevel &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; AUS &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 375.1298 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 22.23860 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14.974584 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 13.43497 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.8690076 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1485925 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 中間50% &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; CAN &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 396.9541 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 19.70919 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 15.624779 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 10.09225 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1342376 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1180077 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 中間50% &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; DEU &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 388.1498 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 26.00656 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 21.126381 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 17.19350 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.5634198 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2317597 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 前面25% &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ESP &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 346.6310 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 23.31459 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 19.716569 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.24174 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.6349016 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2183936 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 中間50% &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; FIN &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 381.1421 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 22.19750 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.537962 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 16.99829 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.0452136 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1562463 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 後面25% &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; FRA &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 309.0471 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.23468 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 13.547131 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 20.06768 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.3049297 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2818803 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; 中間50% &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
---
class: inverse, center
# Data visulization 

---
# Data visulization

```r
library(rworldmap)
library(countrycode)
library(RColorBrewer)
```

**mapCountryData**

```r
cols&lt;-heat.colors(6)
genderMap &lt;- joinCountryData2Map(model.s, joinCode = "ISO3", nameJoinColumn = "country")
```

```
## 15 codes from your data successfully matched countries in the map
## 0 codes from your data failed to match with a country code in the map
## 228 codes from the map weren't represented in your data
```

---

# Data visulization
**mapCountryData**
.pull-left[

```r
mapCountryData(genderMap, nameColumnToPlot = "genderlevel", catMethod = "",
               addLegend = TRUE, missingCountryCol = "white",
               colourPalette = rev(heat.colors(6)),
               mapTitle = 'Gender estimate level in PISA 2012 among 15 countries')
```
]

.pull-right[
![](2020-06-01-Tutorial-Presentation-slide_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;
]

---
# Data visulization
**ggplot**

```r
# Data visualization

library(ggplot2)
library(dplyr)
library(mapproj)
# rename countries to meet the map_data
model.sc&lt;-model.s%&gt;%
  mutate(countries=c("Australia", "Canada", "Germany", 
                     "Spain", "Finland", "France", "United Kingdom",
                     "Indonesia", "Italy","Japan", "Mexico", "Malaysia", 
                     "New Zealand", "Taiwan", "USA"))

WorldData &lt;- map_data('world') %&gt;% filter(region != "Antarctica") %&gt;% fortify
```
---
# Data visulization
**ggplot**

.pull-left[

```r
ggplot() +
  geom_map(data = WorldData, map = WorldData,
           aes(x = long, y = lat, group = group, map_id=region),
           fill = "white", colour = "#7f7f7f", size=0.5) + 
  geom_map(data = model.sc, map=WorldData,
           aes(fill=genderlevel, map_id=countries),
           colour="#7f7f7f", size=0.5) +
  coord_map("rectangular", lat0=0, xlim=c(-180,180), ylim=c(-60, 90)) +
  scale_fill_manual(values=brewer.pal(6, "Reds")) +

  labs(fill="legend", title="Title", x="", y="") +
  theme_bw()
```
]

.pull-right[
![](2020-06-01-Tutorial-Presentation-slide_files/figure-html/unnamed-chunk-31-1.png)&lt;!-- --&gt;
]

---
# Conclusion

--
**We try to simplify r-code, introduce different packages to manipulate the data. There are three useful packages we use in the task:**

--
**package：EdSurvey**
- It can read in and analyze education surveys. e.g.PISA, TIMSS.

--

**package：intsvy**
- It can manipulate PISA data.

--

**package：arsenal**
- Use for large-scale statistical 

---
class: inverse, center, middle

# Thank you for listening
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  /* Replace <script> tags in slides area to make them executable
   *
   * Runs after post-processing of markdown source into slides and replaces only
   * <script>s on the last slide of continued slides using the .has-continuation
   * class added by xaringan. Finally, any <script>s in the slides area that
   * aren't executed are commented out.
   */
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container:not(.has-continuation) script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
  var scriptsNotExecuted = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container.has-continuation script'
  );
  if (!scriptsNotExecuted.length) return;
  for (var i = 0; i < scriptsNotExecuted.length; i++) {
    var comment = document.createComment(scriptsNotExecuted[i].outerHTML)
    scriptsNotExecuted[i].parentElement.replaceChild(comment, scriptsNotExecuted[i])
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
